Unsupervised Learning
Unsupervised learning involves training models on unlabeled data. The goal is to discover hidden patterns or structures in the data.

Common unsupervised learning techniques in deep learning include:
Autoencoders
Generative Adversarial Networks (GANs)
Self-Organizing Maps

Here's a simple implementation of an autoencoder:

import numpy as np

class Autoencoder:
    def __init__(self, input_size, encoding_size):
        self.W1 = np.random.randn(input_size, encoding_size) * 0.01
        self.b1 = np.zeros((1, encoding_size))
        self.W2 = np.random.randn(encoding_size, input_size) * 0.01
        self.b2 = np.zeros((1, input_size))

    def encode(self, X):
        return np.tanh(np.dot(X, self.W1) + self.b1)

    def decode(self, H):
        return np.tanh(np.dot(H, self.W2) + self.b2)

    def forward(self, X):
        self.H = self.encode(X)
        return self.decode(self.H)

    def backward(self, X, output):
        self.dOutput = output - X
        self.dW2 = np.dot(self.H.T, self.dOutput)
        self.db2 = np.sum(self.dOutput, axis=0, keepdims=True)
        self.dH = np.dot(self.dOutput, self.W2.T) * (1 - self.H**2)
        self.dW1 = np.dot(X.T, self.dH)
        self.db1 = np.sum(self.dH, axis=0)

    def train(self, X, epochs, learning_rate):
        for _ in range(epochs):
            output = self.forward(X)
            self.backward(X, output)
            self.W1 -= learning_rate * self.dW1
            self.b1 -= learning_rate * self.db1
            self.W2 -= learning_rate * self.dW2
            self.b2 -= learning_rate * self.db2

# Usage
X = np.random.randn(100, 10)
autoencoder = Autoencoder(input_size=10, encoding_size=5)
autoencoder.train(X, epochs=1000, learning_rate=0.01)

encoded = autoencoder.encode(X)
decoded = autoencoder.decode(encoded)
print("Original shape:", X.shape)
print("Encoded shape:", encoded.
